{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install neurokit2"
      ],
      "metadata": {
        "id": "LD_TmxR0q6cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_Nagzmoytrt"
      },
      "outputs": [],
      "source": [
        "#импорты\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as ptl\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import neurokit2 as nk\n",
        "\n",
        "from scipy.signal import resample\n",
        "from glob import glob\n",
        "from tqdm.auto import tqdm\n",
        "from IPython.display import clear_output\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision import models, transforms\n",
        "from collections import OrderedDict\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#labels\n",
        "\n",
        "\"\"\" {'NORM': 0,\n",
        " 'IMI': 1,\n",
        " 'NDT': 2,\n",
        " 'NST_': 3,\n",
        " 'LVH': 4,\n",
        " 'LAFB': 5,\n",
        " 'IRBBB': 6,\n",
        " 'IVCD': 7,\n",
        " 'ASMI': 8,\n",
        " 'AMI': 9,\n",
        " 'ISCAL': 10,\n",
        " '1AVB': 11,\n",
        " 'ILMI': 12,\n",
        " 'ISC_': 13,\n",
        " 'CRBBB': 14,\n",
        " 'CLBBB': 15,\n",
        " 'LAO/LAE': 16} \"\"\""
      ],
      "metadata": {
        "id": "PVqWeiyh6d2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#подгружаем и распаковываем папку с моделями\n",
        "!gdown http://site.m1r0.webtm.ru:8080/s/ex6dKfgaEqLRJpg/download/models.zip"
      ],
      "metadata": {
        "id": "089E_HfE0zTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip models.zip"
      ],
      "metadata": {
        "id": "wgpJbeeT16dK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ECG NET"
      ],
      "metadata": {
        "id": "2LOf1D0rz_Ao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#архитектура модели\n",
        "\n",
        "class ECGNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ECGNet, self).__init__()\n",
        "    #layer1\n",
        "    self.layer1_conv2d = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(1, 25), stride=(1, 2), bias=True)\n",
        "\n",
        "\n",
        "    #layer2\n",
        "    self.layer2_conv2d = nn.Sequential(OrderedDict([\n",
        "        (\"bn1\", nn.BatchNorm2d(num_features=32)),\n",
        "        (\"act1\", nn.ReLU()),\n",
        "        (\"cn1\", nn.Conv2d(32, 64, kernel_size=(1, 15), stride=(1, 1), bias=True)),\n",
        "        (\"bn2\", nn.BatchNorm2d(num_features=64)),\n",
        "        (\"act2\", nn.ReLU()),\n",
        "        (\"cn2\", nn.Conv2d(64, 64, kernel_size=(1, 15), stride=(1, 2),  bias=True)),\n",
        "        (\"bn3\", nn.BatchNorm2d(num_features=64)),\n",
        "        (\"act3\", nn.ReLU()),\n",
        "        (\"cn3\", nn.Conv2d(64, 32, kernel_size=(1, 15), stride=(1, 1), bias=True)),\n",
        "    ]))\n",
        "    self.layer2_seModule = nn.Sequential(OrderedDict([\n",
        "        (\"fc1\", nn.Conv2d(32, 16, kernel_size=1, bias=True)),\n",
        "        (\"act\", nn.ReLU()),\n",
        "        (\"fc2\", nn.Conv2d(16, 32, kernel_size=1, bias=True)),\n",
        "        (\"gate\", nn.Sigmoid())\n",
        "    ]))\n",
        "\n",
        "    #layer3\n",
        "    self.layer3_conv2d_block1 = nn.Sequential(OrderedDict([\n",
        "        (\"bn1\", nn.BatchNorm2d(num_features=32)),\n",
        "        (\"act1\", nn.ReLU()),\n",
        "        (\"cn1\", nn.Conv2d(32, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=True)),\n",
        "        (\"bn2\", nn.BatchNorm2d(num_features=64)),\n",
        "        (\"act2\", nn.ReLU()),\n",
        "        (\"cn2\", nn.Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=True)),\n",
        "        (\"bn3\", nn.BatchNorm2d(num_features=64)),\n",
        "        (\"act3\", nn.ReLU()),\n",
        "        (\"cn3\", nn.Conv2d(64, 32, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=True)),\n",
        "    ]))\n",
        "    self.layer3_seModule_block1 = nn.Sequential(OrderedDict([\n",
        "        (\"fc1\", nn.Conv2d(32, 16, kernel_size=1, bias=True)),\n",
        "        (\"act\", nn.ReLU()),\n",
        "        (\"fc2\", nn.Conv2d(16, 32, kernel_size=1, bias=True)),\n",
        "        (\"gate\", nn.Sigmoid())\n",
        "    ]))\n",
        "\n",
        "    self.layer3_conv2d_block2 = nn.Sequential(OrderedDict([\n",
        "        (\"bn1\", nn.BatchNorm2d(num_features=32)),\n",
        "        (\"act1\", nn.ReLU()),\n",
        "        (\"cn1\", nn.Conv2d(32, 64, kernel_size=(5, 1), padding=(2, 0), bias=True)),\n",
        "        (\"bn2\", nn.BatchNorm2d(num_features=64)),\n",
        "        (\"act2\", nn.ReLU()),\n",
        "        (\"cn2\", nn.Conv2d(64, 64, kernel_size=(5, 1), padding=(2, 0), bias=True)),\n",
        "        (\"bn3\", nn.BatchNorm2d(num_features=64)),\n",
        "        (\"act3\", nn.ReLU()),\n",
        "        (\"cn3\", nn.Conv2d(64, 32, kernel_size=(5, 1), padding=(2, 0), bias=True)),\n",
        "    ]))\n",
        "    self.layer3_seModule_block2 = nn.Sequential(OrderedDict([\n",
        "        (\"fc1\", nn.Conv2d(32, 16, kernel_size=1, bias=True)),\n",
        "        (\"act\", nn.ReLU()),\n",
        "        (\"fc2\", nn.Conv2d(16, 32, kernel_size=1, bias=True)),\n",
        "        (\"gate\", nn.Sigmoid())\n",
        "    ]))\n",
        "\n",
        "    self.layer3_conv2d_block3 = nn.Sequential(OrderedDict([\n",
        "        (\"bn1\", nn.BatchNorm2d(num_features=32)),\n",
        "        (\"act1\", nn.ReLU()),\n",
        "        (\"cn1\", nn.Conv2d(32, 64, kernel_size=(7, 1), padding=(3, 0), bias=True)),\n",
        "        (\"bn2\", nn.BatchNorm2d(num_features=64)),\n",
        "        (\"act2\", nn.ReLU()),\n",
        "        (\"cn2\", nn.Conv2d(64, 64, kernel_size=(7, 1), padding=(3, 0), bias=True)),\n",
        "        (\"bn3\", nn.BatchNorm2d(num_features=64)),\n",
        "        (\"act3\", nn.ReLU()),\n",
        "        (\"cn3\", nn.Conv2d(64, 32, kernel_size=(7, 1), padding=(3, 0), bias=True)),\n",
        "    ]))\n",
        "    self.layer3_seModule_block3 = nn.Sequential(OrderedDict([\n",
        "        (\"fc1\", nn.Conv2d(32, 16, kernel_size=1, bias=True)),\n",
        "        (\"act\", nn.ReLU()),\n",
        "        (\"fc2\", nn.Conv2d(16, 32, kernel_size=1, bias=True)),\n",
        "        (\"gate\", nn.Sigmoid())\n",
        "    ]))\n",
        "\n",
        "    #layer4\n",
        "    self.layer4_conv1d_short_block1 = nn.Sequential(OrderedDict([\n",
        "        (\"bn1\", nn.BatchNorm1d(num_features=384)),\n",
        "        (\"act1\", nn.ReLU()),\n",
        "        (\"cn1\", nn.Conv1d(384, 384, kernel_size=3, stride=9, bias=True)),\n",
        "    ]))\n",
        "\n",
        "    self.layer4_conv1d_block1 = nn.Sequential(OrderedDict([\n",
        "        (\"bn1\", nn.BatchNorm1d(num_features=384)),\n",
        "        (\"act1\", nn.ReLU()),\n",
        "        (\"cn1\", nn.Conv1d(384, 768, kernel_size=3, stride=2, bias=True)),\n",
        "        (\"bn2\", nn.BatchNorm1d(num_features=768)),\n",
        "        (\"act2\", nn.ReLU()),\n",
        "        (\"cn2\", nn.Conv1d(768, 768, kernel_size=3, stride=1, bias=True)),\n",
        "        (\"bn3\", nn.BatchNorm1d(num_features=768)),\n",
        "        (\"act3\", nn.ReLU()),\n",
        "        (\"cn3\", nn.Conv1d(768, 1536, kernel_size=3, stride=2, bias=True)),\n",
        "        (\"bn4\", nn.BatchNorm1d(num_features=1536)),\n",
        "        (\"act4\", nn.ReLU()),\n",
        "        (\"cn4\", nn.Conv1d(1536, 384, kernel_size=3, stride=2, bias=True)),\n",
        "    ]))\n",
        "    self.layer4_seModule_block1 = nn.Sequential(OrderedDict([\n",
        "        (\"fc1\", nn.Conv1d(384, 48, kernel_size=1, bias=True)),\n",
        "        (\"act\", nn.ReLU()),\n",
        "        (\"fc2\", nn.Conv1d(48, 384, kernel_size=1, bias=True)),\n",
        "        (\"gate\", nn.Sigmoid())\n",
        "    ]))\n",
        "\n",
        "    self.layer4_conv1d_short_block2 = nn.Sequential(OrderedDict([\n",
        "        (\"bn1\", nn.BatchNorm1d(num_features=384)),\n",
        "        (\"act1\", nn.ReLU()),\n",
        "        (\"cn1\", nn.Conv1d(384, 384, kernel_size=5, stride=9, bias=True)),\n",
        "    ]))\n",
        "\n",
        "    self.layer4_conv1d_block2 = nn.Sequential(OrderedDict([\n",
        "        (\"bn1\", nn.BatchNorm1d(num_features=384)),\n",
        "        (\"act1\", nn.ReLU()),\n",
        "        (\"cn1\", nn.Conv1d(384, 768, kernel_size=5, stride=2, padding=2, bias=True)),\n",
        "        (\"bn2\", nn.BatchNorm1d(num_features=768)),\n",
        "        (\"act2\", nn.ReLU()),\n",
        "        (\"cn2\", nn.Conv1d(768, 768, kernel_size=5, stride=2, padding=1, bias=True)),\n",
        "        (\"bn3\", nn.BatchNorm1d(num_features=768)),\n",
        "        (\"act3\", nn.ReLU()),\n",
        "        (\"cn3\", nn.Conv1d(768, 1536, kernel_size=5, stride=1, padding=2, bias=True)),\n",
        "        (\"bn4\", nn.BatchNorm1d(num_features=1536)),\n",
        "        (\"act4\", nn.ReLU()),\n",
        "        (\"cn4\", nn.Conv1d(1536, 384, kernel_size=5, stride=2, padding=1, bias=True)),\n",
        "    ]))\n",
        "    self.layer4_seModule_block2 = nn.Sequential(OrderedDict([\n",
        "        (\"fc1\", nn.Conv1d(384, 48, kernel_size=1, bias=True)),\n",
        "        (\"act\", nn.ReLU()),\n",
        "        (\"fc2\", nn.Conv1d(48, 384, kernel_size=1, bias=True)),\n",
        "        (\"gate\", nn.Sigmoid())\n",
        "    ]))\n",
        "\n",
        "    self.layer4_conv1d_short_block3 = nn.Sequential(OrderedDict([\n",
        "        (\"bn1\", nn.BatchNorm1d(num_features=384)),\n",
        "        (\"act1\", nn.ReLU()),\n",
        "        (\"cn1\", nn.Conv1d(384, 384, kernel_size=7, stride=9, bias=True)),\n",
        "    ]))\n",
        "\n",
        "    self.layer4_conv1d_block3 = nn.Sequential(OrderedDict([\n",
        "        (\"bn1\", nn.BatchNorm1d(num_features=384)),\n",
        "        (\"act1\", nn.ReLU()),\n",
        "        (\"cn1\", nn.Conv1d(384, 768, kernel_size=7, stride=2, padding=2, bias=True)),\n",
        "        (\"bn2\", nn.BatchNorm1d(num_features=768)),\n",
        "        (\"act2\", nn.ReLU()),\n",
        "        (\"cn2\", nn.Conv1d(768, 768, kernel_size=7, stride=2, padding=1, bias=True)),\n",
        "        (\"bn3\", nn.BatchNorm1d(num_features=768)),\n",
        "        (\"act3\", nn.ReLU()),\n",
        "        (\"cn3\", nn.Conv1d(768, 1536, kernel_size=7, stride=1, padding=3, bias=True)),\n",
        "        (\"bn4\", nn.BatchNorm1d(num_features=1536)),\n",
        "        (\"act4\", nn.ReLU()),\n",
        "        (\"cn4\", nn.Conv1d(1536, 384, kernel_size=7, stride=2, padding=2, bias=True)),\n",
        "    ]))\n",
        "    self.layer4_seModule_block3 = nn.Sequential(OrderedDict([\n",
        "        (\"fc1\", nn.Conv1d(384, 48, kernel_size=1, bias=True)),\n",
        "        (\"act\", nn.ReLU()),\n",
        "        (\"fc2\", nn.Conv1d(48, 384, kernel_size=1, bias=True)),\n",
        "        (\"gate\", nn.Sigmoid())\n",
        "    ]))\n",
        "\n",
        "    self.layer5_avg_pool1 = nn.AvgPool1d(kernel_size=10)\n",
        "    self.layer5_avg_pool2 = nn.AvgPool1d(kernel_size=10)\n",
        "    self.layer5_avg_pool3 = nn.AvgPool1d(kernel_size=10)\n",
        "\n",
        "    self.fc = nn.Sequential(OrderedDict([\n",
        "        (\"ln1\", nn.Linear(1152, 288)),\n",
        "        (\"dp\", nn.Dropout(p=0.2)),\n",
        "        (\"act\", nn.ReLU()),\n",
        "        (\"ln2\", nn.Linear(288, 1)),\n",
        "        (\"sigmoid\", nn.Sigmoid())\n",
        "    ]))\n",
        "\n",
        "  def forward(self, x):\n",
        "    #layer1\n",
        "    x = self.layer1_conv2d(x)\n",
        "\n",
        "    #layer2\n",
        "    x = self.layer2_conv2d(x)\n",
        "    u = x\n",
        "    x = x.view(x.size(0), x.size(1), -1).mean(-1).view(x.size(0), x.size(1), 1, 1)\n",
        "    x = self.layer2_seModule(x)\n",
        "    x = u * x\n",
        "\n",
        "    #layer3\n",
        "    x1 = self.layer3_conv2d_block1(x)\n",
        "    u1 = x1\n",
        "    x1 = x1.view(x1.size(0), x1.size(1), -1).mean(-1).view(x1.size(0), x1.size(1), 1, 1)\n",
        "    x1 = self.layer3_seModule_block1(x1)\n",
        "    x1 = u1 * x1\n",
        "\n",
        "    x2 = self.layer3_conv2d_block2(x)\n",
        "    u2 = x2\n",
        "    x2 = x2.view(x2.size(0), x2.size(1), -1).mean(-1).view(x2.size(0), x2.size(1), 1, 1)\n",
        "    x2 = self.layer3_seModule_block2(x2)\n",
        "    x2 = u2 * x2\n",
        "\n",
        "    x3 = self.layer3_conv2d_block3(x)\n",
        "    u3 = x3\n",
        "    x3 = x3.view(x3.size(0), x3.size(1), -1).mean(-1).view(x3.size(0), x3.size(1), 1, 1)\n",
        "    x3 = self.layer3_seModule_block3(x3)\n",
        "    x3 = u3 * x3\n",
        "\n",
        "    #layer4\n",
        "    x1 = torch.flatten(x1, start_dim=1, end_dim=2)\n",
        "    x2 = torch.flatten(x2, start_dim=1, end_dim=2)\n",
        "    x3 = torch.flatten(x3, start_dim=1, end_dim=2)\n",
        "\n",
        "    # x1 = x1.unsqueeze(1)\n",
        "    # x2 = x2.unsqueeze(1)\n",
        "    # x3 = x3.unsqueeze(1)\n",
        "\n",
        "    x1_short = self.layer4_conv1d_short_block1(x1)\n",
        "\n",
        "    x1 = self.layer4_conv1d_block1(x1)\n",
        "    u1 = x1\n",
        "    x1 = x1.view(x1.size(0), x1.size(1), -1).mean(-1).view(x1.size(0), x1.size(1), 1, 1).flatten(2, 3)\n",
        "    x1 = self.layer4_seModule_block1(x1)\n",
        "    x1 = u1 * x1\n",
        "    x1 = x1 + x1_short\n",
        "\n",
        "    x2_short = self.layer4_conv1d_short_block2(x2)\n",
        "\n",
        "    x2 = self.layer4_conv1d_block2(x2)\n",
        "    u2 = x2\n",
        "    x2 = x2.view(x2.size(0), x2.size(1), -1).mean(-1).view(x2.size(0), x2.size(1), 1, 1).flatten(2, 3)\n",
        "    x2 = self.layer4_seModule_block2(x2)\n",
        "    x2 = u2 * x2\n",
        "    x2 = x2 + x2_short\n",
        "\n",
        "    x3_short = self.layer4_conv1d_short_block3(x3)\n",
        "\n",
        "    x3 = self.layer4_conv1d_block3(x3)\n",
        "    u3 = x3\n",
        "    x3 = x3.view(x3.size(0), x3.size(1), -1).mean(-1).view(x3.size(0), x3.size(1), 1, 1).flatten(2, 3)\n",
        "    x3 = self.layer4_seModule_block3(x3)\n",
        "    x3 = u3 * x3\n",
        "    x3 = x3 + x3_short\n",
        "\n",
        "    x1 = self.layer5_avg_pool1(x1)\n",
        "    x2 = self.layer5_avg_pool2(x2)\n",
        "    x3 = self.layer5_avg_pool3(x3)\n",
        "\n",
        "    x = torch.cat((x1, x2, x3), dim=1).flatten(1)\n",
        "\n",
        "    x = self.fc(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "gCok6VdAy44l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#подгрузка моделей"
      ],
      "metadata": {
        "id": "uXbr8E-d0CRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label2id = {'NORM': 0,\n",
        "      'IMI': 1,\n",
        "      'NDT': 2,\n",
        "      'NST': 3,\n",
        "      'LVH': 4,\n",
        "      'LAFB': 5,\n",
        "      'IRBBB': 6,\n",
        "      'IVCD': 7,\n",
        "      'ASMI': 8,\n",
        "      'AMI': 9,\n",
        "      'ISCAL': 10,\n",
        "      '1AVB': 11,\n",
        "      'ILMI': 12,\n",
        "      'ISC': 13,\n",
        "      'CRBBB': 14,\n",
        "      'CLBBB': 15,\n",
        "      'LAO_LAE': 16 }"
      ],
      "metadata": {
        "id": "xySr0PJEzOsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#функция для подгрузки моделей\n",
        "\n",
        "def load_models(root_local_path, model_class):\n",
        "  models = []\n",
        "  paths_local = glob(f\"{root_local_path}*\")\n",
        "  for path in paths_local:\n",
        "    cur_path = glob(f\"{path}/*\")[0]\n",
        "    cur_model = model_class()\n",
        "    cur_model.load_state_dict(torch.load(cur_path))\n",
        "    models.append({\"ill_name\" : cur_path.split(path)[1][1:-10].upper(), \"model\" : cur_model})\n",
        "  return models"
      ],
      "metadata": {
        "id": "cb5YOI2EGgH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#функция для получения предиктов\n",
        "\n",
        "def get_predictions(data, models):\n",
        "\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "    label2id = {'NORM': 0,\n",
        "      'IMI': 1,\n",
        "      'NDT': 2,\n",
        "      'NST': 3,\n",
        "      'LVH': 4,\n",
        "      'LAFB': 5,\n",
        "      'IRBBB': 6,\n",
        "      'IVCD': 7,\n",
        "      'ASMI': 8,\n",
        "      'AMI': 9,\n",
        "      'ISCAL': 10,\n",
        "      '1AVB': 11,\n",
        "      'ILMI': 12,\n",
        "      'ISC': 13,\n",
        "      'CRBBB': 14,\n",
        "      'CLBBB': 15,\n",
        "      'LAO_LAE': 16}\n",
        "\n",
        "    labels_keys = list(label2id.keys())\n",
        "\n",
        "    data = np.apply_along_axis(lambda x: nk.ecg_clean(x, sampling_rate=500), axis=1, arr=data)\n",
        "    peaks = [nk.ecg_findpeaks(data[i])['ECG_R_Peaks'] for i in range(12)]\n",
        "    peaks_count = [(i, len(i)) for i in peaks]\n",
        "    peaks = max(peaks_count, key=lambda x: x[1])[0]\n",
        "    signals = []\n",
        "    for count, i in enumerate(peaks):\n",
        "        if count == 0:\n",
        "            diff2 = abs(peaks[count + 1] - i)\n",
        "            x = 0\n",
        "            y = peaks[count + 1] - diff2 // 2\n",
        "        elif count == len(peaks)-1:\n",
        "            diff1 = abs(peaks[count - 1] - i)\n",
        "            x = peaks[count - 1] + diff1 // 2\n",
        "            y = 5000\n",
        "        else:\n",
        "            diff1 = abs(peaks[count - 1] - i)\n",
        "            diff2 = abs(peaks[count + 1]- i)\n",
        "            x = peaks[count - 1] + diff1 // 2\n",
        "            y = peaks[count + 1] - diff2 // 2\n",
        "\n",
        "        signal = torch.tensor(resample(data[:, x:y], 500, axis=1)).to(device)\n",
        "        signals.append(signal)\n",
        "    signals = torch.stack(signals)[:, None, :, :]\n",
        "\n",
        "    preds = [0] * 17\n",
        "\n",
        "    signals = signals.to(device)\n",
        "    for model_item in models:\n",
        "        model = model_item[\"model\"].to(device)\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            output = torch.mean(model(signals.float()).view(1, -1)[0])\n",
        "            output = float(output.item())\n",
        "            preds[label2id[model_item[\"ill_name\"]]] = \"{:.2f}\".format(output)\n",
        "\n",
        "    return {labels_keys[i] : preds[i] for i in range(17)}"
      ],
      "metadata": {
        "id": "xrp3LcoE8po1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#подгружаем модели\n",
        "models = load_models(\"/content/models/\", ECGNet)\n",
        "\n",
        "#загружаем сигнал из формата .npy\n",
        "data = np.load(f'/content/00669_hr.npy')\n",
        "\n",
        "# получаем предсказания\n",
        "results = get_predictions(data, models)\n",
        "results"
      ],
      "metadata": {
        "id": "04UuHlTaHVgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4OfJOwwseeM6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}